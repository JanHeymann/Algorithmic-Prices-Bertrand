{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firm:\n",
    "    def __init__(self, mc, price_floor, price_cap, learning_rate=0.85, discount_factor=0.9):\n",
    "        self.mc = mc\n",
    "        self.price_floor = price_floor\n",
    "        self.price_cap = price_cap\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.q_table = {}\n",
    "\n",
    "    def get_state(self, price_A, price_B):\n",
    "        return (round(price_A, 2), round(price_B, 2))\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if state not in self.q_table:\n",
    "            self.q_table[state] = {0: 0, 1: 0, 2: 0}\n",
    "        if np.random.rand() < 0.1: \n",
    "            return np.random.choice([0, 1, 2])\n",
    "        else:\n",
    "            return max(self.q_table[state], key=self.q_table[state].get)\n",
    "\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        if next_state not in self.q_table:\n",
    "            self.q_table[next_state] = {0: 0, 1: 0, 2: 0}\n",
    "        best_next_action = max(self.q_table[next_state], key=self.q_table[next_state].get)\n",
    "              \n",
    "        last_price_effect = 0.5 * (next_state[1] - self.mc)\n",
    "        \n",
    "        scaled_reward = reward + last_price_effect\n",
    "        self.q_table[state][action] += self.learning_rate * (scaled_reward + self.discount_factor * self.q_table[next_state][best_next_action] - self.q_table[state][action])\n",
    "    def calculate_profit(self, price):\n",
    "        quantity_sold = 100 - price\n",
    "        return (price - self.mc) * max(quantity_sold, 0)  \n",
    "    \n",
    "    def get_learned_policy(self):\n",
    "        policy = {}\n",
    "        for state, actions in self.q_table.items():\n",
    "            best_action = max(actions, key=actions.get)\n",
    "            policy[state] = best_action\n",
    "        return policy\n",
    "\n",
    "def simulate_bertrand_rl(max_iterations=250000, price_floor=10, price_cap=55, start_price_A=10, start_price_B=10):\n",
    "    firm_A = Firm(mc=10, price_floor=price_floor, price_cap=price_cap)\n",
    "    firm_B = Firm(mc=20, price_floor=price_floor, price_cap=price_cap)\n",
    "\n",
    "    price_A = start_price_A if start_price_A is not None else np.random.uniform(price_floor, price_cap)\n",
    "    price_B = start_price_B if start_price_B is not None else np.random.uniform(price_floor, price_cap)\n",
    "\n",
    "    price_history_A = [start_price_A]\n",
    "    price_history_B = [start_price_B]\n",
    "    reward = []\n",
    "    convergence = []\n",
    "    tolerance = 3\n",
    "    check_interval = 100000\n",
    "    stable_count = 0\n",
    "    min_check_iterations = 500000\n",
    "    Final_Policy = []\n",
    "    actions = []\n",
    "    for i in range(max_iterations):\n",
    "        '''\n",
    "        if (i + 1) % 250000 == 0:\n",
    "            print(f\"Iteration {i + 1}\")\n",
    "        '''\n",
    "        state_A = firm_A.get_state(price_A, price_B)\n",
    "        state_B = firm_B.get_state(price_B, price_A)\n",
    "\n",
    "        action_A = firm_A.get_action(state_A)\n",
    "        action_B = firm_B.get_action(state_B)\n",
    "\n",
    "        if price_history_A[i-1] < price_history_B[i-1]:\n",
    "            price_A = min(price_B, 55)\n",
    "            actions.append(2)\n",
    "        else:\n",
    "            if action_A == 0: \n",
    "                price_A = max(price_A - 1, price_floor)\n",
    "            elif action_A == 2:\n",
    "                price_A = min(price_A + 1, price_cap)\n",
    "            actions.append(action_A)\n",
    "                \n",
    "                \n",
    "        if price_history_A[i-1] > price_history_B[i-1]:\n",
    "            price_B = min(price_history_A[i-1], 55)\n",
    "            actions.append(2)\n",
    "        else:\n",
    "            if action_B == 0:\n",
    "                price_B = max(price_B - 1, price_floor)\n",
    "            elif action_B == 2:\n",
    "                price_B = min(price_B + 1, price_cap)\n",
    "            actions.append(action_B)\n",
    "\n",
    "        if price_A > price_B:  \n",
    "            profit_A = 0\n",
    "            profit_B = firm_B.calculate_profit(price_B)\n",
    "            \n",
    "        if price_A < price_B:\n",
    "            profit_A = firm_A.calculate_profit(price_A)\n",
    "            profit_B = 0\n",
    "        if price_A == price_B:\n",
    "            profit_A = firm_A.calculate_profit(price_A)\n",
    "            profit_B = firm_B.calculate_profit(price_B)\n",
    "        \n",
    "        firm_A.last_price = price_B\n",
    "        firm_B.last_price = price_A\n",
    "\n",
    "        firm_A.update_q_value(state_A, action_A, profit_A, firm_A.get_state(price_A, price_B))\n",
    "        firm_B.update_q_value(state_B, action_B, profit_B, firm_B.get_state(price_B, price_A))\n",
    "\n",
    "        price_history_A.append(price_A)\n",
    "        price_history_B.append(price_B)\n",
    "        reward.append(profit_A)\n",
    "        reward.append(profit_B)\n",
    "        \n",
    "        if i == max_iterations - 1:\n",
    "            Final_Policy.append(firm_B.get_learned_policy())\n",
    "            Final_Policy.append(firm_A.get_learned_policy())\n",
    "    return price_history_A, price_history_B, actions, Final_Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firm_no_effect:\n",
    "    def __init__(self, mc, price_floor, price_cap, learning_rate=0.85, discount_factor=0.9):\n",
    "        self.mc = mc\n",
    "        self.price_floor = price_floor\n",
    "        self.price_cap = price_cap\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.q_table = {}\n",
    "\n",
    "    def get_state(self, price_A, price_B):\n",
    "        return (round(price_A, 2), round(price_B, 2))\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if state not in self.q_table:\n",
    "            self.q_table[state] = {0: 0, 1: 0, 2: 0}\n",
    "        if np.random.rand() < 0.1:\n",
    "            return np.random.choice([0, 1, 2])\n",
    "        else:\n",
    "            return max(self.q_table[state], key=self.q_table[state].get)\n",
    "\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        if next_state not in self.q_table:\n",
    "            self.q_table[next_state] = {0: 0, 1: 0, 2: 0}\n",
    "        best_next_action = max(self.q_table[next_state], key=self.q_table[next_state].get)\n",
    "        \n",
    "        scaled_reward = reward\n",
    "        self.q_table[state][action] += self.learning_rate * (scaled_reward + self.discount_factor * self.q_table[next_state][best_next_action] - self.q_table[state][action])\n",
    "    def calculate_profit(self, price):\n",
    "        quantity_sold = 100 - price\n",
    "        return (price - self.mc) * max(quantity_sold, 0)\n",
    "    \n",
    "    def get_learned_policy(self):\n",
    "        policy = {}\n",
    "        for state, actions in self.q_table.items():\n",
    "            best_action = max(actions, key=actions.get)\n",
    "            policy[state] = best_action\n",
    "        return policy\n",
    "\n",
    "def simulate_bertrand_rl_no_effect(max_iterations=250000, price_floor=10, price_cap=55, start_price_A=10, start_price_B=10):\n",
    "    firm_A = Firm_no_effect(mc=10, price_floor=price_floor, price_cap=price_cap)\n",
    "    firm_B = Firm_no_effect(mc=20, price_floor=price_floor, price_cap=price_cap)\n",
    "\n",
    "    # Set starting prices\n",
    "    price_A = start_price_A if start_price_A is not None else np.random.uniform(price_floor, price_cap)\n",
    "    price_B = start_price_B if start_price_B is not None else np.random.uniform(price_floor, price_cap)\n",
    "\n",
    "    price_history_A = [start_price_A]\n",
    "    price_history_B = [start_price_B]\n",
    "    reward = []\n",
    "    convergence = []\n",
    "    tolerance = 3\n",
    "    check_interval = 100000\n",
    "    stable_count = 0\n",
    "    min_check_iterations = 500000\n",
    "    Final_Policy = []\n",
    "    actions = []\n",
    "    for i in range(max_iterations):\n",
    "        '''\n",
    "        if (i + 1) % 250000 == 0:\n",
    "            print(f\"Iteration {i + 1}\")\n",
    "        '''\n",
    "        state_A = firm_A.get_state(price_A, price_B)\n",
    "        state_B = firm_B.get_state(price_B, price_A)\n",
    "\n",
    "        action_A = firm_A.get_action(state_A)\n",
    "        action_B = firm_B.get_action(state_B)\n",
    "\n",
    "        if price_history_A[i-1] < price_history_B[i-1]:\n",
    "            price_A = min(price_B, 55)\n",
    "            actions.append(2)\n",
    "        else:\n",
    "            if action_A == 0:\n",
    "                price_A = max(price_A - 1, price_floor)\n",
    "            elif action_A == 2:\n",
    "                price_A = min(price_A + 1, price_cap)\n",
    "            actions.append(action_A)\n",
    "                \n",
    "                \n",
    "        if price_history_A[i-1] > price_history_B[i-1]:\n",
    "            price_B = min(price_history_A[i-1], 55)\n",
    "            actions.append(2)\n",
    "        else:\n",
    "            if action_B == 0:\n",
    "                price_B = max(price_B - 1, price_floor)\n",
    "            elif action_B == 2:\n",
    "                price_B = min(price_B + 1, price_cap)\n",
    "            actions.append(action_B)\n",
    "\n",
    "        if price_A > price_B:  \n",
    "            profit_A = 0\n",
    "            profit_B = firm_B.calculate_profit(price_B)\n",
    "            \n",
    "        if price_A < price_B:\n",
    "            profit_A = firm_A.calculate_profit(price_A)\n",
    "            profit_B = 0\n",
    "        if price_A == price_B:\n",
    "            profit_A = firm_A.calculate_profit(price_A)\n",
    "            profit_B = firm_B.calculate_profit(price_B)\n",
    "        \n",
    "        firm_A.last_price = price_B\n",
    "        firm_B.last_price = price_A\n",
    "\n",
    "        firm_A.update_q_value(state_A, action_A, profit_A, firm_A.get_state(price_A, price_B))\n",
    "        firm_B.update_q_value(state_B, action_B, profit_B, firm_B.get_state(price_B, price_A))\n",
    "\n",
    "        price_history_A.append(price_A)\n",
    "        price_history_B.append(price_B)\n",
    "        reward.append(profit_A)\n",
    "        reward.append(profit_B)\n",
    "        \n",
    "        if i == max_iterations - 1:\n",
    "            Final_Policy.append(firm_B.get_learned_policy())\n",
    "            Final_Policy.append(firm_A.get_learned_policy())\n",
    "    return price_history_A, price_history_B, actions, Final_Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "21\n",
      "31\n",
      "41\n",
      "51\n",
      "61\n",
      "71\n",
      "81\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "start_price_A = 10\n",
    "start_price_B = 10\n",
    "with open('convergence_no_effect.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for t in range(0, 100):\n",
    "        if t < 50:\n",
    "            price_history_A, price_history_B, reward, time = simulate_bertrand_rl(start_price_A=start_price_A, start_price_B=start_price_B)\n",
    "            writer.writerow([price_history_B[-1]])\n",
    "        else:\n",
    "            price_history_A, price_history_B, reward, time = simulate_bertrand_rl_no_effect(start_price_A=start_price_A, start_price_B=start_price_B)\n",
    "            writer.writerow([price_history_B[-1]])\n",
    "            \n",
    "        if t % 10 == 0:\n",
    "            print(t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 0.3037\n",
      "P-value: 0.7620\n",
      "No statistically significant difference between the two halves.\n",
      "\n",
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\begin{tabular}{lcc}\n",
      "\\hline\n",
      " & With Price Effect & Without Price Effect \\\\\n",
      "\\hline\n",
      "Number of Observations & 50 & 49 \\\\\n",
      "Mean & 51.8000 & 51.5714 \\\\\n",
      "Standard Deviation & 3.4756 & 3.9279 \\\\\n",
      "\\hline\n",
      "\\multicolumn{3}{l}{T-statistic: 0.3037} \\\\\n",
      "\\multicolumn{3}{l}{P-value: 0.7620} \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{T-test Analysis of With Price Effect vs. Without Price Effect}\n",
      "\\label{tab:t_test_price_effect}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('convergence_no_effect.csv')\n",
    "\n",
    "# Split the data into two halves\n",
    "first_half = data.iloc[:50].values.flatten()\n",
    "second_half = data.iloc[50:].values.flatten()\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_stat, p_value = ttest_ind(first_half, second_half)\n",
    "\n",
    "# Calculate additional statistics\n",
    "mean_first = first_half.mean()\n",
    "std_first = first_half.std()\n",
    "n_first = len(first_half)\n",
    "\n",
    "mean_second = second_half.mean()\n",
    "std_second = second_half.std()\n",
    "n_second = len(second_half)\n",
    "\n",
    "# Print the results\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference between the two halves is statistically significant.\")\n",
    "else:\n",
    "    print(\"No statistically significant difference between the two halves.\")\n",
    "\n",
    "# Create a LaTeX table\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[ht]\n",
    "\\\\centering\n",
    "\\\\begin{{tabular}}{{lcc}}\n",
    "\\\\hline\n",
    " & With Price Effect & Without Price Effect \\\\\\\\\n",
    "\\\\hline\n",
    "Number of Observations & {n_first} & {n_second} \\\\\\\\\n",
    "Mean & {mean_first:.4f} & {mean_second:.4f} \\\\\\\\\n",
    "Standard Deviation & {std_first:.4f} & {std_second:.4f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\multicolumn{{3}}{{l}}{{T-statistic: {t_stat:.4f}}} \\\\\\\\\n",
    "\\\\multicolumn{{3}}{{l}}{{P-value: {p_value:.4f}}} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\caption{{T-test Analysis of With Price Effect vs. Without Price Effect}}\n",
    "\\\\label{{tab:t_test_price_effect}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
